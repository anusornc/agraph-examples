{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586ed92c-8877-415b-ae94-1d9791dcb71e",
   "metadata": {},
   "source": [
    "# Graph Analytics by AllegroGraph and Apache Spark\n",
    "\n",
    "[Apache Spark](https://spark.apache.org/) is one of the most popular platforms for large-scale data processing. In addition to machine learning, SQL database solutions, Spark also comes with [GraphX](https://spark.apache.org/graphx/) and [GraphFrames](https://graphframes.github.io/graphframes/docs/_site/index.html) two frameworks for running graph compute operations on your data. In this notebook, we will show you how to read data from AllegroGraph and then perform graph analytics by Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7545812-7277-4e21-9d10-f142564fc20c",
   "metadata": {},
   "source": [
    "## Apache Spark Basics\n",
    "\n",
    "Apache Spark was built on top of Hadoop MapReduce and it extends the MapReduce model to efficiently use more types of computations. It provides interfaces (inlcuding interactive shells) for programming entire clusters with implicit data parallelism and fault-tolerance. For a quick start of more Spark APIs, please go to [here](https://spark.apache.org/docs/latest/quick-start.html).\n",
    "\n",
    "**SparkContext** is the entry gate of Apache Spark functionality. The next cell shows some basic parameters of the current *SparkContext*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5654a69f-de15-41e5-b8cb-019b81f2ca15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://e1f149c677d5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://spark-master:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=spark://spark-master:7077 appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e4f381-2b5a-40ca-b2ab-600ec9a1d6c3",
   "metadata": {},
   "source": [
    "The entry point into all functionality in Spark SQL is the **SQLContext** class. The next cell shows an instance of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58ec85f-388d-4d55-85fd-7d828957e90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x7f53dc870710>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5784ca4-a6ca-4fd9-b245-1616ec15e127",
   "metadata": {},
   "source": [
    "## Set up AllegroGraph connection to repository _kennedy_\n",
    "\n",
    "An instance of AllegroGraph is running in the a Docker network (port **10035**) where our Spark cluster is also running within. However, if you want to access the WebView page, please visit [http://localhost:10015](http://localhost:10015) instead.\n",
    "\n",
    "In this example we are using a Kennedy family graph. It is a rather small dataset as our main focus is to transform RDF triples to what Spark and GraphFrames need as input.\n",
    "\n",
    "![Kenney](img/kennedy.png)\n",
    "\n",
    "The next cell displays our parameters for connecting to AllegroGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e4a302-af7e-4736-b696-71f61abfafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from franz.openrdf.connect import ag_connect\n",
    "from franz.openrdf.query.query import QueryLanguage\n",
    "\n",
    "conn_args = {\n",
    "    \"host\": \"ag\",\n",
    "    \"port\": 10035,\n",
    "    \"user\": \"test\",\n",
    "    \"password\": \"xyzzy\",\n",
    "    \"create\": False,\n",
    "    \"clear\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799f6e4b-3752-48da-8d8b-522059de41a3",
   "metadata": {},
   "source": [
    "## _Person_ DataFrame\n",
    "\n",
    "Before Spark version 1.6, users have to use the [**RDD**](https://spark.apache.org/docs/latest/rdd-programming-guide.html) API to achieve parallel computation. Starting from version 1.6, **Dataset** is a new interface added that provides the benefits of RDDs (strong typing, ability to use powerful lambda functions) with the benefits of Spark SQL’s optimized execution engine. Finally, a **DataFrame** is a Dataset organized into named columns. It is conceptually equivalent to a table in a relational database. \n",
    "\n",
    "In the next cell, we use a SPARQL query to collect people's metadata (including first name, last name, sex and birth year), and then use `sqlContext.createDataFrame` method to construct a DataFrame. Note that we are using the IRI as each row's identifier (column `id`). As shortly we will see, this is what GraphFrames want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf5e512-6670-4661-ac45-818bc812441b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 people collected in total\n",
      "+--------------------+----------+-----------+------+----------+\n",
      "|                  id|first_name|  last_name|   sex|birth_year|\n",
      "+--------------------+----------+-----------+------+----------+\n",
      "|http://www.franz....|    Joseph|    Kennedy|  male|      1888|\n",
      "|http://www.franz....|      Rose| Fitzgerald|female|      1890|\n",
      "|http://www.franz....|    Robert|    Shriver|  male|      1915|\n",
      "|http://www.franz....|    Joseph|    Kennedy|  male|      1915|\n",
      "|http://www.franz....|   William|  Cavendish|  male|      1917|\n",
      "|http://www.franz....|      John|    Kennedy|  male|      1917|\n",
      "|http://www.franz....|      Rose|    Kennedy|female|      1918|\n",
      "|http://www.franz....|  Kathleen|    Kennedy|female|      1920|\n",
      "|http://www.franz....|    Eunice|    Kennedy|female|      1921|\n",
      "|http://www.franz....|     Peter|    Lawford|  male|      1923|\n",
      "|http://www.franz....|  Patricia|    Kennedy|female|      1924|\n",
      "|http://www.franz....|    Robert|    Kennedy|  male|      1925|\n",
      "|http://www.franz....|   Stephen|      Smith|female|      1927|\n",
      "|http://www.franz....|      Jean|    Kennedy|female|      1928|\n",
      "|http://www.franz....|     Ethel|     Skakel|female|      1928|\n",
      "|http://www.franz....|Jacqueline|    Bouvier|female|      1929|\n",
      "|http://www.franz....|    Edward|    Kennedy|  male|      1932|\n",
      "|http://www.franz....|  Virginia|    Bennett|female|      1936|\n",
      "|http://www.franz....|     Edwin|Schlossberg|  male|      1945|\n",
      "|http://www.franz....|     David|   Townsend|  male|      1947|\n",
      "+--------------------+----------+-----------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def person_iter():\n",
    "    q = \"\"\"PREFIX : <http://www.franz.com/simple#>\n",
    "SELECT DISTINCT ?person ?first_name ?last_name ?sex ?birth_year {\n",
    "  ?person a :person ;\n",
    "        :first-name ?first_name ;\n",
    "        :last-name ?last_name ;\n",
    "        :sex ?sex ;\n",
    "        :birth-year ?birth_year .           \n",
    "}\n",
    "ORDER BY ?birth_year\"\"\"\n",
    "    with ag_connect(\"kennedy\", **conn_args) as conn:\n",
    "        with conn.prepareTupleQuery(QueryLanguage.SPARQL, q).evaluate() as res:\n",
    "            for binding_set in res:\n",
    "                person_iri = binding_set.getValue(\"person\").getURI()\n",
    "                first_name = binding_set.getValue(\"first_name\").toPython()\n",
    "                last_name = binding_set.getValue(\"last_name\").toPython()\n",
    "                sex = binding_set.getValue(\"sex\").getLocalName()\n",
    "                birth_year = int(binding_set.getValue(\"birth_year\").toPython())\n",
    "                yield (person_iri, first_name, last_name, sex, birth_year)\n",
    "                \n",
    "df_person = sqlContext.createDataFrame(person_iter(), (\"id\", \"first_name\", \"last_name\", \"sex\", \"birth_year\"))\n",
    "print(\"{:,} people collected in total\".format(df_person.count()))\n",
    "df_person.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d7a1f0-bb8d-4823-8389-7bc636494fce",
   "metadata": {},
   "source": [
    "## _Relations_ DataFrame\n",
    "\n",
    "The next step is to collect **relations** information among people. We will aim at these 3 types of relations:\n",
    "\n",
    "1. Spouce\n",
    "2. Has Child\n",
    "3. Has Parent\n",
    "\n",
    "Similar to how we construct the person DataFrame, we do it again by using a SPARQL query. Meanwhile, note that we have two special columns `src` and `dst` that are important for constructing the final graph in next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd31b179-4bc1-4c55-acfd-2a0dc3b73926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226 relations collected in total\n",
      "+--------------------+--------------------+--------+\n",
      "|                 src|                 dst|relation|\n",
      "+--------------------+--------------------+--------+\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "|http://www.franz....|http://www.franz....|  spouse|\n",
      "+--------------------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def relation_iter(rel: str):\n",
    "    q = f\"\"\"PREFIX : <http://www.franz.com/simple#>\n",
    "SELECT DISTINCT ?p1 ?p2 {{\n",
    "  ?p1 a :person .\n",
    "  ?p2 a :person .\n",
    "  ?p1 :{rel} ?p2 .\n",
    "}}\"\"\"\n",
    "    with ag_connect(\"kennedy\", **conn_args) as conn:\n",
    "        with conn.prepareTupleQuery(QueryLanguage.SPARQL, q).evaluate() as res:\n",
    "            for binding_set in res:\n",
    "                p1_iri = binding_set.getValue(\"p1\").getURI()\n",
    "                p2_iri = binding_set.getValue(\"p2\").getURI()\n",
    "                yield (p1_iri, p2_iri, rel)\n",
    "\n",
    "all_relations = chain(*[relation_iter(rel) for rel in (\"spouse\", \"has-child\", \"has-parent\")])\n",
    "df_relation = sqlContext.createDataFrame(all_relations, (\"src\", \"dst\", \"relation\"))\n",
    "print(\"{:,} relations collected in total\".format(df_relation.count()))\n",
    "df_relation.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd9fc7-46af-488e-967e-32762d2085f2",
   "metadata": {},
   "source": [
    "## GraphX and GraphFrames\n",
    "\n",
    "[GraphX](https://spark.apache.org/graphx/) is a Spark component for graphs and graph-parallel computation. Just like Dataset and DataFrame are higher-level APIs to RDD, [GraphFrames](https://graphframes.github.io/graphframes/docs/_site/index.html) provide both the functionality of GraphX and extended functionality taking advantage of Spark DataFrames. In this tutorial, we will use GraphFrames.\n",
    "\n",
    "To create GraphFrames, vertex and edge DataFrames are needed:\n",
    "\n",
    "* Vertex DataFrame: A vertex DataFrame should contain a special column named “id” which specifies unique IDs for each vertex in the graph.\n",
    "* Edge DataFrame: An edge DataFrame should contain two special columns: “src” (source vertex ID of edge) and “dst” (destination vertex ID of edge).\n",
    "\n",
    "In the cell below, we use the _person_ DataFrame and also the _relation_ DataFrame as the Vertex and Edge respectively. Finally, the variable `g` is the an instance of our GraphFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e52e92-9bea-4c29-a3b8-a639ade1dfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "\n",
    "g = GraphFrame(\n",
    "    df_person, # vertices\n",
    "    df_relation, # edges\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e475b99-980d-4f32-a118-12befe3fd3a8",
   "metadata": {},
   "source": [
    "## Graph Analysis\n",
    "\n",
    "We can start using `g` to perform various graph analytics provided by GraphFrames APIs, including but not limited to:\n",
    "    \n",
    "* [Motif finding](https://graphframes.github.io/graphframes/docs/_site/user-guide.html#motif-finding)\n",
    "* [Connected components](https://graphframes.github.io/graphframes/docs/_site/user-guide.html#connected-components)\n",
    "* [Label Propagation Algorithm](https://graphframes.github.io/graphframes/docs/_site/user-guide.html#label-propagation-algorithm-lpa)\n",
    "* [PageRank](https://graphframes.github.io/graphframes/docs/_site/user-guide.html#pagerank)\n",
    "\n",
    "For more APIs information, please visit [GraphFrames User Guides](https://graphframes.github.io/graphframes/docs/_site/user-guide.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c88d75-2189-4c80-888f-4baec18fd322",
   "metadata": {},
   "source": [
    "### PageRank\n",
    "\n",
    "We are doing a simple PageRank analysis in the next cell. The results indicates that [Robert Kennedy](https://en.wikipedia.org/wiki/Robert_F._Kennedy) is very \"important\" in the family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ab10e8c-cc2e-4d84-be4a-8e6b32fe972b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+------------------+\n",
      "|first_name |last_name |birth_year|pagerank          |\n",
      "+-----------+----------+----------+------------------+\n",
      "|Robert     |Kennedy   |1925      |4.029459626495298 |\n",
      "|Ethel      |Skakel    |1928      |3.576717463298322 |\n",
      "|Joseph     |Kennedy   |1888      |2.6219862110262917|\n",
      "|Rose       |Fitzgerald|1890      |2.6219862110262917|\n",
      "|Eunice     |Kennedy   |1921      |2.298703166856844 |\n",
      "|Edward     |Kennedy   |1932      |2.0938386383501943|\n",
      "|Patricia   |Kennedy   |1924      |2.0240009400459353|\n",
      "|Jean       |Kennedy   |1928      |1.9843031856876374|\n",
      "|Robert     |Shriver   |1915      |1.8386363287897425|\n",
      "|John       |Kennedy   |1917      |1.7415387136767322|\n",
      "|Peter      |Lawford   |1923      |1.560736771187538 |\n",
      "|Stephen    |Smith     |1927      |1.5226742073189046|\n",
      "|Mary       |Kennedy   |1956      |1.4077893004500306|\n",
      "|Joseph     |Kennedy   |1952      |1.4077893004500306|\n",
      "|Robert     |Kennedy   |1954      |1.4077893004500306|\n",
      "|Virginia   |Bennett   |1936      |1.3052524218905863|\n",
      "|Jacqueline |Bouvier   |1929      |1.273968076578413 |\n",
      "|Kara       |Kennedy   |1960      |1.0696412446441306|\n",
      "|Edward     |Kennedy   |1961      |1.0696412446441306|\n",
      "|Victoria   |Lawford   |1958      |1.0418845118029045|\n",
      "|Sydney     |Lawford   |1956      |1.0418845118029045|\n",
      "|Christopher|Lawford   |1955      |1.0418845118029045|\n",
      "|Caroline   |Kennedy   |1957      |1.0412688857049155|\n",
      "|John       |Kennedy   |1960      |1.0412688857049155|\n",
      "|Maria      |Shriver   |1955      |1.0339110450576012|\n",
      "|Anthony    |Shriver   |1965      |1.0339110450576012|\n",
      "|Timothy    |Shriver   |1959      |1.0339110450576012|\n",
      "|Mark       |Shriver   |1964      |1.0339110450576012|\n",
      "|Michael    |Kennedy   |1958      |1.0255615716869297|\n",
      "|Rory       |Kennedy   |1968      |1.0255615716869297|\n",
      "+-----------+----------+----------+------------------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "results = g.pageRank(resetProbability=0.15, tol=0.01)\n",
    "results.vertices.select(\"first_name\", \"last_name\", \"birth_year\", \"pagerank\") \\\n",
    "    .orderBy(desc(\"pagerank\")) \\\n",
    "    .show(30, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
